{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F5.wav', 'F4.wav', 'F3.wav', 'F2.wav', 'F1.wav', 'M1.wav', 'M2.wav', 'M3.wav', 'M4.wav', 'M5.wav']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from types import SimpleNamespace\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import correlate\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"data/pitch/test\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def autocorr_method(frame, sfreq, threshold=0.55, fmin=50, fmax=400):\n",
    "    \"\"\"Estimate pitch using autocorrelation\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate autocorrelation using scipy correlate\n",
    "    frame = frame.astype(np.float)\n",
    "    frame -= frame.mean()\n",
    "    amax = np.abs(frame).max()\n",
    "    if amax > 0:\n",
    "        frame /= amax\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    corr = correlate(frame, frame)\n",
    "    # keep the positive part\n",
    "    corr = corr[len(corr)//2:]\n",
    "\n",
    "    # Find the first minimum\n",
    "    dcorr = np.diff(corr)\n",
    "    rmin = np.where(dcorr > 0)[0]\n",
    "    if len(rmin) > 0:\n",
    "        rmin1 = rmin[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    # Find the next peak\n",
    "    peak = np.argmax(corr[rmin1:]) + rmin1\n",
    "    rmax = corr[peak]/corr[0]\n",
    "    f0 = sfreq / peak\n",
    "\n",
    "    if rmax > threshold and f0 >= fmin and f0 <= fmax:\n",
    "        return f0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0c7be69d4071f45f46430daf4015fa8c1145d4da"
   },
   "outputs": [],
   "source": [
    "class Counters:\n",
    "    def __init__(self, gross_threshold=0.2):\n",
    "        self.num_voiced = 0\n",
    "        self.num_unvoiced = 0\n",
    "        self.num_voiced_unvoiced = 0\n",
    "        self.num_unvoiced_voiced = 0\n",
    "        self.num_voiced_voiced = 0\n",
    "        self.num_gross_errors = 0\n",
    "        self.fine_error = 0\n",
    "        self.e2 = 0\n",
    "        self.gross_threshold = gross_threshold\n",
    "        self.nfiles = 0\n",
    "\n",
    "    def add(self, other):\n",
    "        if other is not None:\n",
    "            self.num_voiced += other.num_voiced\n",
    "            self.num_unvoiced += other.num_unvoiced\n",
    "            self.num_voiced_unvoiced += other.num_voiced_unvoiced\n",
    "            self.num_unvoiced_voiced += other.num_unvoiced_voiced\n",
    "            self.num_voiced_voiced += other.num_voiced_voiced\n",
    "            self.num_gross_errors += other.num_gross_errors\n",
    "            self.fine_error += other.fine_error\n",
    "            self.e2 += other.e2\n",
    "            self.nfiles += 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        nframes = self.num_voiced + self.num_unvoiced\n",
    "        if self.nfiles > 0:\n",
    "            self.fine_error /= self.nfiles\n",
    "        str = [\n",
    "            f\"Num. frames:\\t{self.num_unvoiced + self.num_voiced} = {self.num_unvoiced} unvoiced + {self.num_voiced} voiced\",\n",
    "            f\"Unvoiced frames as voiced:\\t{self.num_unvoiced_voiced}/{self.num_unvoiced} ({100*self.num_unvoiced_voiced/self.num_unvoiced:.2f}%)\",\n",
    "            f\"Voiced frames as unvoiced:\\t{self.num_voiced_unvoiced}/{self.num_voiced} ({100*self.num_voiced_unvoiced/self.num_voiced:.2f}%)\",\n",
    "            f\"Gross voiced errors (>{100*self.gross_threshold}%):\\t{self.num_gross_errors}/{self.num_voiced_voiced} ({100*self.num_gross_errors/self.num_voiced_voiced:.2f}%)\",\n",
    "            f\"MSE of fine errors:\\t{100*self.fine_error:.2f}%\",\n",
    "            f\"RMSE:\\t{np.sqrt(self.e2/nframes):.2f}\"\n",
    "        ]\n",
    "        return '\\n'.join(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e9870d63a5eb733ef6b98f3305b3c2634608bf3f"
   },
   "outputs": [],
   "source": [
    "def compare(fref, pitch):\n",
    "    vref = np.loadtxt(fref)\n",
    "    vtest = np.array(pitch)\n",
    "\n",
    "    diff_frames = len(vref) - len(vtest)\n",
    "    if abs(diff_frames) > 5:\n",
    "        print(f\"Error: number of frames in ref ({len(vref)}) != number of frames in test ({len(vtest)})\")\n",
    "        return None\n",
    "    elif diff_frames > 0:\n",
    "        vref = np.resize(vref, vtest.shape)\n",
    "    elif diff_frames < 0:\n",
    "        vtest = np.resize(vtest, vref.shape)\n",
    "\n",
    "    counters = Counters()\n",
    "    counters.num_voiced = np.count_nonzero(vref)\n",
    "    counters.num_unvoiced = len(vref) - counters.num_voiced\n",
    "    counters.num_unvoiced_voiced = np.count_nonzero(np.logical_and(vref == 0, vtest != 0))\n",
    "    counters.num_voiced_unvoiced = np.count_nonzero(np.logical_and(vref != 0, vtest == 0))\n",
    "\n",
    "    voiced_voiced = np.logical_and(vref != 0, vtest != 0)\n",
    "    counters.num_voiced_voiced = np.count_nonzero(voiced_voiced)\n",
    "\n",
    "    f = np.absolute(vref[voiced_voiced] - vtest[voiced_voiced])/vref[voiced_voiced]\n",
    "    gross_errors = f > counters.gross_threshold\n",
    "    counters.num_gross_errors = np.count_nonzero(gross_errors)\n",
    "    fine_errors = np.logical_not(gross_errors)\n",
    "    counters.fine_error = np.sqrt(np.square(f[fine_errors]).mean())\n",
    "    counters.e2 = np.square(vref - vtest).sum()\n",
    "\n",
    "    return counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "37f3e70917faeb9e5f47d1d53b910ce07bc944a3"
   },
   "outputs": [],
   "source": [
    "def wav2f0(options, gui):\n",
    "    fs = open(options.submission, 'w') if options.submission is not None else None\n",
    "    totalCounters = Counters()\n",
    "    with open(gui) as f:\n",
    "        if fs is not None:\n",
    "            print('id,frequency', file=fs)\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            filename = os.path.join(options.datadir, line + \".wav\")\n",
    "            f0ref_filename = os.path.join(options.datadir, line + \".f0ref\")\n",
    "            # print(\"Processing:\", filename)\n",
    "            sfreq, data = wavfile.read(filename)\n",
    "            nsamples = len(data)\n",
    "\n",
    "            # From miliseconds to samples\n",
    "            ns_windowlength = int(round((options.windowlength * sfreq) / 1000))\n",
    "            ns_frameshift = int(round((options.frameshift * sfreq) / 1000))\n",
    "            ns_left_padding = int(round((options.left_padding * sfreq) / 1000))\n",
    "            ns_right_padding = int(round((options.right_padding * sfreq) / 1000))\n",
    "            pitch = []\n",
    "            for id, ini in enumerate(range(-ns_left_padding, nsamples - ns_windowlength + ns_right_padding + 1, ns_frameshift)):\n",
    "                first_sample = max(0, ini)\n",
    "                last_sample = min(nsamples, ini + ns_windowlength)\n",
    "                frame = data[first_sample:last_sample]\n",
    "                f0 = autocorr_method(frame, sfreq)\n",
    "                # print(f0)\n",
    "                if fs is not None:\n",
    "                    print(line + '_' + str(id) + ',', f0, file=fs)\n",
    "                pitch.append(f0)\n",
    "\n",
    "            if os.path.isfile(f0ref_filename):\n",
    "                counters = compare(f0ref_filename, pitch)\n",
    "                totalCounters.add(counters)\n",
    "\n",
    "    if totalCounters.num_voiced + totalCounters.num_unvoiced > 0:\n",
    "        print(\"### Summary\")\n",
    "        print(totalCounters)\n",
    "        print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "f611c950eeb79b40456612db424113d5837ac9ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Summary\n",
      "Num. frames:\t22140 = 13916 unvoiced + 8224 voiced\n",
      "Unvoiced frames as voiced:\t221/13916 (1.59%)\n",
      "Voiced frames as unvoiced:\t2009/8224 (24.43%)\n",
      "Gross voiced errors (>20.0%):\t19/6215 (0.31%)\n",
      "MSE of fine errors:\t1.87%\n",
      "RMSE:\t55.73\n",
      "-------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fda_ue_options = SimpleNamespace(\n",
    "    windowlength=32, frameshift=15, left_padding=16, right_padding=16, datadir='data', submission=None)\n",
    "wav2f0(fda_ue_options, 'data/pitch/fda_ue.gui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fda_ue_options = SimpleNamespace(\n",
    "    windowlength=32, frameshift=10, left_padding=0, right_padding=0, datadir='data', submission=None)\n",
    "wav2f0(fda_ue_options, 'data/pitch/ptdb_tug.gui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "74599d24c27013ae1a90007812b76e9dc576a903"
   },
   "outputs": [],
   "source": [
    "test_options = SimpleNamespace(\n",
    "    windowlength=26.5, frameshift=10, left_padding=13.25, right_padding=7, datadir='data/pitch/test', submission='autocorrelation_method_submission.csv')\n",
    "wav2f0(test_options, 'data/pitch/test.gui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
